# HUIT Q&A API

HUIT Q&A API l√† m·ªôt h·ªá th·ªëng tr·∫£ l·ªùi c√¢u h·ªèi t·ª± ƒë·ªông v·ªÅ th√¥ng tin tuy·ªÉn sinh c·ªßa Tr∆∞·ªùng ƒê·∫°i h·ªçc C√¥ng nghi·ªáp TP.HCM (HUIT). API s·ª≠ d·ª•ng **cache** ƒë·ªÉ tr·∫£ l·ªùi nhanh c√°c c√¢u h·ªèi ph·ªï bi·∫øn v√† **RAG (Retrieval-Augmented Generation)** ƒë·ªÉ x·ª≠ l√Ω c√°c c√¢u h·ªèi ph·ª©c t·∫°p, k·∫øt h·ª£p v·ªõi l·ªãch s·ª≠ h·ªôi tho·∫°i ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh.

## C·∫•u tr√∫c h·ªá th·ªëng
- **Cache**:
  - L∆∞u tr·ªØ 710+ c√¢u h·ªèi ph·ªï bi·∫øn t·ª´ file Excel `BO_250_CAU_HOI_CUA_SINH_VIEN.xlsx`.
  - S·ª≠ d·ª•ng Qdrant local (`question_collection`) ƒë·ªÉ t√¨m ki·∫øm c√¢u h·ªèi t∆∞∆°ng t·ª± d·ª±a tr√™n embedding.
  - Model: `keepitreal/vietnamese-sbert` cho embedding ti·∫øng Vi·ªát.
- **RAG**:
  - T√¨m ki·∫øm t√†i li·ªáu t·ª´ collection `cam_nang_tuyen_sinh_HUIT_2025` (171 points) tr√™n Qdrant cloud.
  - K·∫øt h·ª£p OpenAI (`gpt-4o-mini`) ƒë·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi chi ti·∫øt.
- **History**:
  - L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i theo `session_id` ƒë·ªÉ duy tr√¨ ng·ªØ c·∫£nh.
- **API**:
  - ƒê∆∞·ª£c x√¢y d·ª±ng b·∫±ng FastAPI, ch·∫°y tr√™n `http://0.0.0.0:8000`.
  - Endpoint ch√≠nh: `POST /process`.

## Y√™u c·∫ßu
- **H·ªá ƒëi·ªÅu h√†nh**: Windows, Linux, ho·∫∑c macOS.
- **Python**: 3.8+.
- **Docker**: ƒê·ªÉ ch·∫°y Qdrant local.
- **API Keys**:
  - `OPENAI_API_KEY`: Cho OpenAI (`gpt-3.5-turbo`).
  - `QDRANT_API_KEY`: Cho Qdrant cloud.
- **Dung l∆∞·ª£ng**: ~2GB RAM cho Qdrant v√† `sentence-transformers`.

## C√†i ƒë·∫∑t
1. **Clone repository**:
   ```bash
   git clone <your-repo-url>
   cd <your-repo-folder>
   ```

2. **T·∫°o file `.env`**:
  T·∫°o file `.env` trong th∆∞ m·ª•c g·ªëc v·ªõi n·ªôi dung:
  ```
  # Qdrant configuration (RAG)
  export QDRANT_API_KEY=your_key
  export QDRANT_URL=your_url
  export QDRANT_PORT=6333
  QDRANT_COLLECTION=cam nang tuyen sinh HUIT 2025

  # Qdrant configuration (Cache)
  QDRANT_HOST=localhost
  QDRANT_CACHE_PORT=6333
  QDRANT_CACHE_COLLECTION=question_collection
  QDRANT_TOP_K=5

  # OpenAI configuration
  OPENAI_API_KEY=your_key
  OPENAI_MODEL_NAME=gpt-4o-mini

  # Model configuration
  LLM_MODEL_NAME=gpt-4o-mini
  EMBEDDING_MODEL_NAME=dangvantuan/vietnamese-document-embedding

  # Retriever configuration (RAG)
  RETRIEVER_K=10
  RETRIEVER_SCORE_THRESHOLD=0.5
  MAX_REWRITE_ROUNDS=3

  # Data paths
  ABBREVIATION_FILE=data/viettat.xlsx
  QUESTION_FILE=data/B·ªò 250 C√ÇU H·ªéI C·ª¶A SINH VI√äN V·ªÄ TR∆Ø·ªúNG ƒê·∫†I H·ªåC C√îNG TH∆Ø∆†NG TP.HCM.xlsx
   ```

3. **C√†i ƒë·∫∑t Python dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
   File `requirements.txt` n√™n c√≥:
   ```
   fastapi
   uvicorn
   pandas
   openai
   qdrant-client
   sentence-transformers
   pyvi
   python-dotenv
   langchain
   langchain-openai
   httpx
   ```

4. **Ch·∫°y Qdrant local**:
   ```bash
   docker run -d -p 6333:6333 qdrant/qdrant
   ```
   Ki·ªÉm tra Qdrant:
   ```bash
   curl http://localhost:6333
   ```

## Ch·∫°y d·ª± √°n
1. **Kh·ªüi ƒë·ªông API**:
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000 --reload
   ```
   - `--reload`: T·ª± ƒë·ªông restart khi s·ª≠a code (cho dev).
   - Log s·∫Ω hi·ªÉn th·ªã:
     ```
     INFO: Application startup complete.
     INFO: Cache collection question_collection exists with 710 points.
     INFO: Collection cam_nang_tuyen_sinh_HUIT_2025 already has 171 points.
     ```

2. **Test API**:
   D√πng `curl` ƒë·ªÉ g·ª≠i c√¢u h·ªèi:
   ```bash
   curl -X POST "http://localhost:8000/process" -H "Content-Type: application/json" -d "{\"question\": \"Ng√†nh n√†o ƒëi·ªÉm cao nh·∫•t?\"}"
   ```
   Response m·∫´u:
   ```
   C√¢u h·ªèi ph√π h·ª£p trong cache: Ng√†nh n√†o c√≥ ƒëi·ªÉm chu·∫©n cao nh·∫•t t·∫°i HUIT?
   Tr·∫£ l·ªùi: Ng√†nh C√¥ng ngh·ªá th√¥ng tin c√≥ ƒëi·ªÉm chu·∫©n cao nh·∫•t, th∆∞·ªùng dao ƒë·ªông t·ª´ 26-27 ƒëi·ªÉm.
   ```
   Ho·∫∑c (n·∫øu cache miss):
   ```
   Kh√¥ng t√¨m th·∫•y trong cache, x·ª≠ l√Ω b·∫±ng RAG
   Tr·∫£ l·ªùi: Ng√†nh C√¥ng ngh·ªá th√¥ng tin t·∫°i HUIT c√≥ ƒëi·ªÉm chu·∫©n cao nh·∫•t...
   ```

## API Endpoint
- **POST `/process`**:
  - **Input**:
    ```json
    {
      "question": "Ng√†nh n√†o ƒëi·ªÉm cao nh·∫•t?"
    }
    ```
    - Header (t√πy ch·ªçn): `session-id` ƒë·ªÉ duy tr√¨ l·ªãch s·ª≠ h·ªôi tho·∫°i.
  - **Output**:
    - Cache hit: Tr·∫£ v·ªÅ c√¢u h·ªèi kh·ªõp v√† c√¢u tr·∫£ l·ªùi.
    - Cache miss: D√πng RAG ƒë·ªÉ tr·∫£ l·ªùi.
    - L·ªói: JSON v·ªõi `error` v√† m√£ tr·∫°ng th√°i (400, 500).
  - **Media type**: `text/plain` (stream).

## D·ªØ li·ªáu
- **Excel**: `data/xlsx/BO_250_CAU_HOI_CUA_SINH_VIEN.xlsx`
  - C·ªôt: `STT`, `C√¢u h·ªèi`, `C√¢u tr·∫£ l·ªùi`.
  - D√πng ƒë·ªÉ t·∫°o cache (`question_collection`).
- **Qdrant**:
  - Local: `question_collection` (710 points).
  - Cloud: `cam_nang_tuyen_sinh_HUIT_2025` (171 points).

## Ghi ch√∫
- **Debug**: Xem log trong terminal ho·∫∑c th√™m logging v√†o file:
  ```python
  logging.basicConfig(handlers=[logging.FileHandler("api.log"), logging.StreamHandler()])
  ```
- **T·ªëi ∆∞u cache**: Th√™m c√¢u h·ªèi ph·ªï bi·∫øn v√†o Excel ƒë·ªÉ tƒÉng t·ª∑ l·ªá cache hit.
- **M·∫°ng**: ƒê·∫£m b·∫£o k·∫øt n·ªëi ·ªïn ƒë·ªãnh t·ªõi OpenAI v√† Qdrant cloud.

## Li√™n h·ªá
- C√≥ v·∫•n ƒë·ªÅ? Li√™n h·ªá "s·∫øp" qua <your-email> ho·∫∑c m·ªü issue tr√™n repo! üòÑ